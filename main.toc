\changetocdepth {4}
\babel@toc {brazil}{}\relax 
\contentsline {chapter}{Sum\'ario}{3}{section*.2}%
\setlength {\cftchapterindent }{\cftlastnumwidth } \setlength {\cftchapternumwidth }{2em}
\contentsline {part}{\partnumberline {I}\MakeTextUppercase []{História da IA e do Computador}}{13}{part.1}%
\setlength {\cftchapterindent }{0em} \setlength {\cftchapternumwidth }{\cftlastnumwidth }
\contentsline {chapter}{\chapternumberline {1}\MakeTextUppercase []{Uma Breve História do Computador}}{15}{chapter.1}%
\contentsline {section}{\numberline {1.1}A Necessidade de Contar ao Longo das Eras}{15}{section.1.1}%
\contentsline {subsection}{\numberline {1.1.1}Ábaco}{15}{subsection.1.1.1}%
\contentsline {subsection}{\numberline {1.1.2}Régua de Cálculo}{15}{subsection.1.1.2}%
\contentsline {subsection}{\numberline {1.1.3}Bastões de Napier}{15}{subsection.1.1.3}%
\contentsline {subsection}{\numberline {1.1.4}Pascalina}{15}{subsection.1.1.4}%
\setlength {\cftchapterindent }{0em} \setlength {\cftchapternumwidth }{\cftlastnumwidth }
\contentsline {chapter}{\chapternumberline {2}\MakeTextUppercase []{Uma Breve História da Inteligência Artificial}}{17}{chapter.2}%
\contentsline {section}{\numberline {2.1}Os Anos 1900}{17}{section.2.1}%
\contentsline {section}{\numberline {2.2}Os Anos 1910}{17}{section.2.2}%
\contentsline {section}{\numberline {2.3}Os Anos 1920}{17}{section.2.3}%
\contentsline {section}{\numberline {2.4}Os Anos 1930}{17}{section.2.4}%
\contentsline {section}{\numberline {2.5}Os Anos 1940}{17}{section.2.5}%
\contentsline {section}{\numberline {2.6}Os Anos 1950}{17}{section.2.6}%
\contentsline {section}{\numberline {2.7}Os Anos 1960}{17}{section.2.7}%
\contentsline {section}{\numberline {2.8}Os Anos 1970}{17}{section.2.8}%
\contentsline {section}{\numberline {2.9}Os Anos 1980}{17}{section.2.9}%
\contentsline {section}{\numberline {2.10}Os Anos 1990}{17}{section.2.10}%
\contentsline {section}{\numberline {2.11}Os Anos 2000}{17}{section.2.11}%
\contentsline {section}{\numberline {2.12}Atualidade}{17}{section.2.12}%
\contentsline {part}{\partnumberline {II}\MakeTextUppercase []{Conceitos Matemáticos}}{19}{part.2}%
\setlength {\cftchapterindent }{0em} \setlength {\cftchapternumwidth }{\cftlastnumwidth }
\contentsline {chapter}{\chapternumberline {3}\MakeTextUppercase []{Cálculo para Aprendizado de Máquina}}{21}{chapter.3}%
\contentsline {section}{\numberline {3.1}Funções: A Base do Cálculo}{21}{section.3.1}%
\contentsline {section}{\numberline {3.2}Derivadas Ordinárias}{21}{section.3.2}%
\contentsline {section}{\numberline {3.3}Integrais Simples}{21}{section.3.3}%
\contentsline {section}{\numberline {3.4}Derivadas Parciais}{21}{section.3.4}%
\setlength {\cftchapterindent }{0em} \setlength {\cftchapternumwidth }{\cftlastnumwidth }
\contentsline {chapter}{\chapternumberline {4}\MakeTextUppercase []{Álgebra Linear para Aprendizado de Máquina}}{23}{chapter.4}%
\contentsline {section}{\numberline {4.1}A Unidade Fundamental: Vetores e Espaços Vetoriais}{23}{section.4.1}%
\contentsline {section}{\numberline {4.2}Organizando Dados: Matrizes e Suas Operações}{23}{section.4.2}%
\contentsline {section}{\numberline {4.3}Tensores: A Estrutura de Dados do Deep Learning}{23}{section.4.3}%
\contentsline {section}{\numberline {4.4}Resolvendo Sistemas e Encontrando Propriedades: Autovalores e Autovetores}{23}{section.4.4}%
\contentsline {section}{\numberline {4.5}Decomposição de Matrizes (SVD e PCA)}{23}{section.4.5}%
\setlength {\cftchapterindent }{0em} \setlength {\cftchapternumwidth }{\cftlastnumwidth }
\contentsline {chapter}{\chapternumberline {5}\MakeTextUppercase []{Probabilidade e Estatística para Aprendizado de Máquina}}{25}{chapter.5}%
\contentsline {section}{\numberline {5.1}Medindo a Incerteza: Probabilidade Básica e Condicional}{25}{section.5.1}%
\contentsline {section}{\numberline {5.2}O Teorema de Bayes: Aprendendo com Evidências}{25}{section.5.2}%
\contentsline {section}{\numberline {5.3}Descrevendo os Dados: Estatística Descritiva: Média, mediana, variância, desvio padrão}{25}{section.5.3}%
\contentsline {section}{\numberline {5.4}Variáveis Aleatórias e Distribuições de Probabilidade}{25}{section.5.4}%
\contentsline {section}{\numberline {5.5}A Função de Máxima Verossimilhança (Maximum Likelihood Estimation - MLE)}{25}{section.5.5}%
\contentsline {part}{\partnumberline {III}\MakeTextUppercase []{Pilares das Redes Neurais}}{27}{part.3}%
\setlength {\cftchapterindent }{0em} \setlength {\cftchapternumwidth }{\cftlastnumwidth }
\contentsline {chapter}{\chapternumberline {6}\MakeTextUppercase []{O Algoritmo da Repropropagação e Os Otimizadores Baseados em Gradiente}}{29}{chapter.6}%
\contentsline {section}{\numberline {6.1}O Método do Gradiente Descendente: O Motor da Retropropagação}{30}{section.6.1}%
\contentsline {subsection}{\numberline {6.1.1}Exemplo Ilustrativo: Cadeia de Montanhas}{30}{subsection.6.1.1}%
\contentsline {subsection}{\numberline {6.1.2}O Método em Si}{31}{subsection.6.1.2}%
\contentsline {section}{\numberline {6.2}A Retropropagação: Aprendendo com os Erros}{34}{section.6.2}%
\contentsline {subsection}{\numberline {6.2.1}Utilizando o Gradiente Descendente para Atualizar os Pesos e Vieses}{40}{subsection.6.2.1}%
\contentsline {subsection}{\numberline {6.2.2}Entendendo Como o Gradiente É Propagado ao Longo de Muitas Camadas}{42}{subsection.6.2.2}%
\contentsline {section}{\numberline {6.3}Otimizadores Baseados em Gradiente: Melhorando o Gradiente Descendente}{44}{section.6.3}%
\contentsline {subsection}{\numberline {6.3.1}Método do Gradiente com Momento}{45}{subsection.6.3.1}%
\contentsline {subsection}{\numberline {6.3.2}Método do Gradiente Estocástico (SGD)}{47}{subsection.6.3.2}%
\contentsline {subsection}{\numberline {6.3.3}Método do Gradiente em Mini-Batch (GD mini-batch)}{49}{subsection.6.3.3}%
\contentsline {subsection}{\numberline {6.3.4}Gradiente Acelerado de Nesterov (NAG)}{49}{subsection.6.3.4}%
\contentsline {subsection}{\numberline {6.3.5}Comparativo de Otimizadores Clássicos}{52}{subsection.6.3.5}%
\contentsline {section}{\numberline {6.4}Otimizadores Modernos Baseados em Gradiente: A Era das Taxas de Aprendizado Adaptativas}{53}{section.6.4}%
\contentsline {subsection}{\numberline {6.4.1}Adadptive Gradient Algorithm (AdaGrad)}{53}{subsection.6.4.1}%
\contentsline {subsection}{\numberline {6.4.2}Root Mean Square Propagation (RMSProp)}{57}{subsection.6.4.2}%
\contentsline {subsection}{\numberline {6.4.3}Adaptive Moment Estimation (Adam)}{58}{subsection.6.4.3}%
\contentsline {subsection}{\numberline {6.4.4}AdaMax}{61}{subsection.6.4.4}%
\contentsline {subsection}{\numberline {6.4.5}Nesterov-accelerated Adaptive Moment Estimation (Nadam)}{63}{subsection.6.4.5}%
\contentsline {subsection}{\numberline {6.4.6}Adam With Decoupled Weight Decay (AdamW)}{65}{subsection.6.4.6}%
\contentsline {subsection}{\numberline {6.4.7}Comparativo dos Otimizadores Modernos}{68}{subsection.6.4.7}%
\contentsline {subsection}{\numberline {6.4.8}Outros Otimizadores}{68}{subsection.6.4.8}%
\contentsline {section}{\numberline {6.5}Comparativo de Desempenho: Otimizadores}{69}{section.6.5}%
\contentsline {section}{\numberline {6.6}O Método de Newton: Indo Além do Gradiente}{69}{section.6.6}%
\contentsline {subsection}{\numberline {6.6.1}Conceitos iniciais: Matrizes Jacobianas e Hessianas}{70}{subsection.6.6.1}%
\contentsline {subsection}{\numberline {6.6.2}O Método}{70}{subsection.6.6.2}%
\setlength {\cftchapterindent }{0em} \setlength {\cftchapternumwidth }{\cftlastnumwidth }
\contentsline {chapter}{\chapternumberline {7}\MakeTextUppercase []{Funções de Ativação Sigmoidais}}{73}{chapter.7}%
\contentsline {section}{\numberline {7.1}Teoremas da Aproximação Universal: Introduzindo a Não-Linearidade}{73}{section.7.1}%
\contentsline {section}{\numberline {7.2}Propriedades das Funções de Ativação: Escolhendo Uma Boa Função de Ativação}{76}{section.7.2}%
\contentsline {section}{\numberline {7.3}Exemplo Ilustrativo: Empurrando para Extremos}{78}{section.7.3}%
\contentsline {section}{\numberline {7.4}A Sigmoide Logística: Ótima para Classificações Binárias}{78}{section.7.4}%
\contentsline {section}{\numberline {7.5}Tangente Hiperbólica: A Pioneira nas Redes Convolucionais}{83}{section.7.5}%
\contentsline {section}{\numberline {7.6}Softsign: Uma Sigmoidal Mais Barata}{86}{section.7.6}%
\contentsline {section}{\numberline {7.7}Hard Sigmoid e Hard Tanh: O Sacrifício da Suavidade em Prol do Desempenho}{88}{section.7.7}%
\contentsline {section}{\numberline {7.8}O Desaparecimento de Gradientes}{91}{section.7.8}%
\contentsline {section}{\numberline {7.9}Comparativo: Funções Sigmoidais}{94}{section.7.9}%
\setlength {\cftchapterindent }{0em} \setlength {\cftchapternumwidth }{\cftlastnumwidth }
\contentsline {chapter}{\chapternumberline {8}\MakeTextUppercase []{Funções de Ativação Retificadoras}}{97}{chapter.8}%
\contentsline {section}{\numberline {8.1}Exemplo Ilustrativo: Vendendo Pipoca}{97}{section.8.1}%
\contentsline {section}{\numberline {8.2}Rectified Linear Unit (ReLU): A Revolução Retificadora}{98}{section.8.2}%
\contentsline {section}{\numberline {8.3}O Problema dos ReLUs Agonizantes}{104}{section.8.3}%
\contentsline {section}{\numberline {8.4}As Variantes com Vazamento: Corrigindo o Problema do ReLUs agonizantes}{104}{section.8.4}%
\contentsline {subsection}{\numberline {8.4.1}Leaky ReLU (LReLU)}{105}{subsection.8.4.1}%
\contentsline {subsection}{\numberline {8.4.2}Parametric ReLU (PReLU)}{109}{subsection.8.4.2}%
\contentsline {subsection}{\numberline {8.4.3}Randomized Leaky ReLU (RReLU)}{115}{subsection.8.4.3}%
\contentsline {section}{\numberline {8.5}As Variantes Não Lineares: Em Busca da Suavidade}{119}{section.8.5}%
\contentsline {subsection}{\numberline {8.5.1}Exponential Linear Unit (ELU)}{120}{subsection.8.5.1}%
\contentsline {subsection}{\numberline {8.5.2}Scaled Exponential Linear Unit (SELU)}{123}{subsection.8.5.2}%
\contentsline {subsection}{\numberline {8.5.3}Noisy ReLU (NReLU)}{127}{subsection.8.5.3}%
\contentsline {section}{\numberline {8.6}O Problema dos Gradientes Explosivos}{132}{section.8.6}%
\contentsline {section}{\numberline {8.7}Comparativo: Funções Retificadoras}{135}{section.8.7}%
\setlength {\cftchapterindent }{0em} \setlength {\cftchapternumwidth }{\cftlastnumwidth }
\contentsline {chapter}{\chapternumberline {9}\MakeTextUppercase []{Funções de Ativação Modernas e Outras Funções de Ativação}}{137}{chapter.9}%
\contentsline {section}{\numberline {9.1}Funções Modernas: O Estado-da-Arte das Funções de Ativação}{137}{section.9.1}%
\contentsline {subsection}{\numberline {9.1.1}Gaussian Error Linear Unit (GELU)}{137}{subsection.9.1.1}%
\contentsline {subsection}{\numberline {9.1.2}Swish}{141}{subsection.9.1.2}%
\contentsline {section}{\numberline {9.2}Funções Para Camadas de Saída}{142}{section.9.2}%
\contentsline {subsection}{\numberline {9.2.1}Softmax}{142}{subsection.9.2.1}%
\setlength {\cftchapterindent }{0em} \setlength {\cftchapternumwidth }{\cftlastnumwidth }
\contentsline {chapter}{\chapternumberline {10}\MakeTextUppercase []{Funções de Perda para Regressão}}{143}{chapter.10}%
\contentsline {section}{\numberline {10.1}A Intuição da Perda: Medindo o Erro do Modelo}{143}{section.10.1}%
\contentsline {section}{\numberline {10.2}Exemplo Ilustrativo: Jogando Dados}{143}{section.10.2}%
\contentsline {section}{\numberline {10.3}Funções de Perda para Regressão para Propósitos Gerais}{144}{section.10.3}%
\contentsline {subsection}{\numberline {10.3.1}Erro Quadrático Médio (Mean Squared Error - MSE)}{144}{subsection.10.3.1}%
\contentsline {subsection}{\numberline {10.3.2}Erro Absoluto Médio (Mean Absolute Error - MAE)}{148}{subsection.10.3.2}%
\contentsline {subsection}{\numberline {10.3.3}Huber Loss: O Melhor de Dois Mundos}{151}{subsection.10.3.3}%
\contentsline {subsection}{\numberline {10.3.4}Perda Log-Cosh}{153}{subsection.10.3.4}%
\contentsline {section}{\numberline {10.4}Lidando com a Escala: Foco no Erro Relativo}{156}{section.10.4}%
\contentsline {subsection}{\numberline {10.4.1}Erro Quadrático Médio Logarítmico (MSLE)}{157}{subsection.10.4.1}%
\contentsline {subsection}{\numberline {10.4.2}Erro Percentual Absoluto Médio (MAPE)}{158}{subsection.10.4.2}%
\contentsline {subsection}{\numberline {10.4.3}Erro Percentual Absoluto Médio Simétrico (sMAPE)}{160}{subsection.10.4.3}%
\contentsline {section}{\numberline {10.5}Mudando o Objetivo da Previsão: Além da Média}{160}{section.10.5}%
\contentsline {subsection}{\numberline {10.5.1}Perda Quantílica}{160}{subsection.10.5.1}%
\contentsline {subsection}{\numberline {10.5.2}Perda Epsilon-Insensível}{162}{subsection.10.5.2}%
\contentsline {section}{\numberline {10.6}Perdas Baseadas em Distribuições de Dados}{162}{section.10.6}%
\contentsline {subsection}{\numberline {10.6.1}Perda de Poisson}{162}{subsection.10.6.1}%
\contentsline {subsection}{\numberline {10.6.2}Perda de Tweedie}{165}{subsection.10.6.2}%
\contentsline {subsection}{\numberline {10.6.3}Divergência Kullback-Leibler}{165}{subsection.10.6.3}%
\contentsline {section}{\numberline {10.7}Comparativo: Funções de Perda para Regressão}{167}{section.10.7}%
\contentsline {section}{\numberline {10.8}Fluxograma: Escolhendo a Função de Perda Ideal}{167}{section.10.8}%
\setlength {\cftchapterindent }{0em} \setlength {\cftchapternumwidth }{\cftlastnumwidth }
\contentsline {chapter}{\chapternumberline {11}\MakeTextUppercase []{Funções de Perda para Classificação}}{169}{chapter.11}%
\contentsline {section}{\numberline {11.1}Exemplo Ilustrativo:}{169}{section.11.1}%
\contentsline {section}{\numberline {11.2}Funções de Perda para Classificação Binária}{169}{section.11.2}%
\contentsline {subsection}{\numberline {11.2.1}Entropia Cruzada Binária (Binary Cross-Entropy - BCE): A função de perda padrão}{169}{subsection.11.2.1}%
\contentsline {subsection}{\numberline {11.2.2}Entropia Cruzada Ponderada Binária (Binary Weighted Cross-Entropy -WCE)}{173}{subsection.11.2.2}%
\contentsline {subsection}{\numberline {11.2.3}Perda Hinge (Hinge Loss)}{175}{subsection.11.2.3}%
\contentsline {subsection}{\numberline {11.2.4}Squared Hinge Loss}{178}{subsection.11.2.4}%
\contentsline {section}{\numberline {11.3}Funções de Perda para Classificação Multi-Classe}{180}{section.11.3}%
\contentsline {subsection}{\numberline {11.3.1}Exemplo Ilustrativo:}{180}{subsection.11.3.1}%
\contentsline {subsection}{\numberline {11.3.2}Entropia Cruzada Categórica (Categorical Cross-Entropy - CCE)}{180}{subsection.11.3.2}%
\contentsline {subsection}{\numberline {11.3.3}Entropia Cruzada Categórica Esparsa (Sparse Categorical Cross-Entropy)}{185}{subsection.11.3.3}%
\contentsline {subsection}{\numberline {11.3.4}Weighted Categorical Cross-Entropy (WCCE)}{185}{subsection.11.3.4}%
\contentsline {section}{\numberline {11.4}Multilabel Loss}{186}{section.11.4}%
\contentsline {section}{\numberline {11.5}Comparativo: Funções de Perda para Classificação}{186}{section.11.5}%
\contentsline {section}{\numberline {11.6}Fluxograma: Escolhendo a Função de Perda Ideal}{186}{section.11.6}%
\setlength {\cftchapterindent }{0em} \setlength {\cftchapternumwidth }{\cftlastnumwidth }
\contentsline {chapter}{\chapternumberline {12}\MakeTextUppercase []{Funções de Perda para Usos Específicos}}{189}{chapter.12}%
\contentsline {section}{\numberline {12.1}Focal Loss}{189}{section.12.1}%
\contentsline {section}{\numberline {12.2}Fluxograma:}{189}{section.12.2}%
\setlength {\cftchapterindent }{0em} \setlength {\cftchapternumwidth }{\cftlastnumwidth }
\contentsline {chapter}{\chapternumberline {13}\MakeTextUppercase []{Métricas de Avaliação}}{191}{chapter.13}%
\contentsline {section}{\numberline {13.1}Métricas de Avaliação}{191}{section.13.1}%
\contentsline {subsection}{\numberline {13.1.1}Acurácia}{191}{subsection.13.1.1}%
\contentsline {subsection}{\numberline {13.1.2}Precisão}{191}{subsection.13.1.2}%
\contentsline {subsection}{\numberline {13.1.3}Revocação ou Sensibilidade}{191}{subsection.13.1.3}%
\contentsline {subsection}{\numberline {13.1.4}F1-Score}{191}{subsection.13.1.4}%
\contentsline {subsection}{\numberline {13.1.5}Curva ROC e AUC}{191}{subsection.13.1.5}%
\contentsline {subsection}{\numberline {13.1.6}Métricas Para Regressão ($R^2$)}{192}{subsection.13.1.6}%
\setlength {\cftchapterindent }{0em} \setlength {\cftchapternumwidth }{\cftlastnumwidth }
\contentsline {chapter}{\chapternumberline {14}\MakeTextUppercase []{Autodiff}}{193}{chapter.14}%
\contentsline {section}{\numberline {14.1}Técnicas de Diferenciação}{193}{section.14.1}%
\contentsline {section}{\numberline {14.2}Autodiff Direta}{193}{section.14.2}%
\contentsline {subsection}{\numberline {14.2.1}Autodiff Direta}{193}{subsection.14.2.1}%
\contentsline {subsection}{\numberline {14.2.2}Autodiff Direta Com Números Duais}{193}{subsection.14.2.2}%
\contentsline {section}{\numberline {14.3}Autodiff Reversa}{193}{section.14.3}%
\setlength {\cftchapterindent }{0em} \setlength {\cftchapternumwidth }{\cftlastnumwidth }
\contentsline {chapter}{\chapternumberline {15}\MakeTextUppercase []{Metaheurísticas: Otimizando Redes Neurais Sem o Gradiente}}{195}{chapter.15}%
\contentsline {section}{\numberline {15.1}Algoritmos Evolutivos}{195}{section.15.1}%
\contentsline {section}{\numberline {15.2}Inteligência de Enxame}{195}{section.15.2}%
\contentsline {part}{\partnumberline {IV}\MakeTextUppercase []{Aprendizado de Máquina Clássico}}{197}{part.4}%
\setlength {\cftchapterindent }{0em} \setlength {\cftchapternumwidth }{\cftlastnumwidth }
\contentsline {chapter}{\chapternumberline {16}\MakeTextUppercase []{Técnicas de Regressão}}{199}{chapter.16}%
\contentsline {section}{\numberline {16.1}Exemplo Ilustrativo}{199}{section.16.1}%
\contentsline {section}{\numberline {16.2}Regressão Linear}{199}{section.16.2}%
\contentsline {subsection}{\numberline {16.2.1}Função de Custo MSE}{199}{subsection.16.2.1}%
\contentsline {subsection}{\numberline {16.2.2}Equação Normal}{199}{subsection.16.2.2}%
\contentsline {subsection}{\numberline {16.2.3}Implementação em Python}{199}{subsection.16.2.3}%
\contentsline {section}{\numberline {16.3}Regressão Polininomial}{199}{section.16.3}%
\contentsline {subsection}{\numberline {16.3.1}Impletanção em Python}{199}{subsection.16.3.1}%
\contentsline {section}{\numberline {16.4}Regressão de Ridge}{199}{section.16.4}%
\contentsline {subsection}{\numberline {16.4.1}Implementação em Python}{199}{subsection.16.4.1}%
\contentsline {section}{\numberline {16.5}Regressão de Lasso}{199}{section.16.5}%
\contentsline {subsection}{\numberline {16.5.1}Implementação em Python}{199}{subsection.16.5.1}%
\contentsline {section}{\numberline {16.6}Elastic Net}{199}{section.16.6}%
\contentsline {subsection}{\numberline {16.6.1}Implementação em Python}{199}{subsection.16.6.1}%
\contentsline {section}{\numberline {16.7}Regressão Logística}{199}{section.16.7}%
\contentsline {subsection}{\numberline {16.7.1}Implementação em Python}{199}{subsection.16.7.1}%
\contentsline {section}{\numberline {16.8}Regressão Softmax}{199}{section.16.8}%
\contentsline {subsection}{\numberline {16.8.1}Implementação em Python}{199}{subsection.16.8.1}%
\contentsline {section}{\numberline {16.9}Outras Técnicas de Regressão}{199}{section.16.9}%
\setlength {\cftchapterindent }{0em} \setlength {\cftchapternumwidth }{\cftlastnumwidth }
\contentsline {chapter}{\chapternumberline {17}\MakeTextUppercase []{Árvores de Decisão e Florestas Aleatórias}}{201}{chapter.17}%
\contentsline {section}{\numberline {17.1}Exemplo Ilustrativo}{201}{section.17.1}%
\contentsline {section}{\numberline {17.2}Entendendo o Conceito de Árvores}{201}{section.17.2}%
\contentsline {subsection}{\numberline {17.2.1}Árvores Binárias}{201}{subsection.17.2.1}%
\contentsline {section}{\numberline {17.3}Árvores de Decisão}{201}{section.17.3}%
\contentsline {subsection}{\numberline {17.3.1}Implementação em Python}{201}{subsection.17.3.1}%
\contentsline {section}{\numberline {17.4}Florestas Aleatórias}{201}{section.17.4}%
\contentsline {subsection}{\numberline {17.4.1}Implementação em Python}{201}{subsection.17.4.1}%
\setlength {\cftchapterindent }{0em} \setlength {\cftchapternumwidth }{\cftlastnumwidth }
\contentsline {chapter}{\chapternumberline {18}\MakeTextUppercase []{Máquinas de Vetores de Suporte}}{203}{chapter.18}%
\contentsline {section}{\numberline {18.1}Exemplo Ilustrativo}{203}{section.18.1}%
\setlength {\cftchapterindent }{0em} \setlength {\cftchapternumwidth }{\cftlastnumwidth }
\contentsline {chapter}{\chapternumberline {19}\MakeTextUppercase []{Ensamble}}{205}{chapter.19}%
\contentsline {section}{\numberline {19.1}Exemplo Ilustrativo}{205}{section.19.1}%
\setlength {\cftchapterindent }{0em} \setlength {\cftchapternumwidth }{\cftlastnumwidth }
\contentsline {chapter}{\chapternumberline {20}\MakeTextUppercase []{Dimensionalidade}}{207}{chapter.20}%
\contentsline {section}{\numberline {20.1}Exemplo Ilustrativo}{207}{section.20.1}%
\contentsline {section}{\numberline {20.2}A Maldição da Dimensionalidade}{207}{section.20.2}%
\contentsline {section}{\numberline {20.3}Seleção de Características (Feature Selection)}{207}{section.20.3}%
\contentsline {section}{\numberline {20.4}Extração de Características (Feature Extraction)}{207}{section.20.4}%
\contentsline {subsection}{\numberline {20.4.1}Análise de Componentes Principais (PCA)}{207}{subsection.20.4.1}%
\contentsline {subsection}{\numberline {20.4.2}t-SNE (t-Distributed Stochastic Neighbor Embedding) e UMAP}{207}{subsection.20.4.2}%
\setlength {\cftchapterindent }{0em} \setlength {\cftchapternumwidth }{\cftlastnumwidth }
\contentsline {chapter}{\chapternumberline {21}\MakeTextUppercase []{Clusterização}}{209}{chapter.21}%
\contentsline {section}{\numberline {21.1}Exemplo Ilustrativo}{209}{section.21.1}%
\contentsline {section}{\numberline {21.2}Aprendizado Não Supervisionado: Encontrando Grupos nos Dados}{209}{section.21.2}%
\contentsline {section}{\numberline {21.3}Clusterização Particional: K-Means}{209}{section.21.3}%
\contentsline {section}{\numberline {21.4}Clusterização Hierárquica}{209}{section.21.4}%
\contentsline {section}{\numberline {21.5}Clusterização Baseada em Densidade: DBSCAN}{209}{section.21.5}%
\contentsline {part}{\partnumberline {V}\MakeTextUppercase []{Redes Neurais Profundas (DNNs)}}{211}{part.5}%
\setlength {\cftchapterindent }{0em} \setlength {\cftchapternumwidth }{\cftlastnumwidth }
\contentsline {chapter}{\chapternumberline {22}\MakeTextUppercase []{Perceptrons MLP - Redes Neurais Artificiais}}{213}{chapter.22}%
\setlength {\cftchapterindent }{0em} \setlength {\cftchapternumwidth }{\cftlastnumwidth }
\contentsline {chapter}{\chapternumberline {23}\MakeTextUppercase []{Redes FeedForward (FFNs)}}{215}{chapter.23}%
\setlength {\cftchapterindent }{0em} \setlength {\cftchapternumwidth }{\cftlastnumwidth }
\contentsline {chapter}{\chapternumberline {24}\MakeTextUppercase []{Redes de Crença Profunda (DBNs) e Máquinas de Boltzmann Restritas}}{217}{chapter.24}%
\setlength {\cftchapterindent }{0em} \setlength {\cftchapternumwidth }{\cftlastnumwidth }
\contentsline {chapter}{\chapternumberline {25}\MakeTextUppercase []{Redes Neurais Convolucionais (CNN)}}{220}{chapter.25}%
\contentsline {section}{\numberline {25.1}Exemplo Ilustrativo}{220}{section.25.1}%
\contentsline {section}{\numberline {25.2}Camadas Convolucionais: O Bloco Fundamental para as CNNs}{220}{section.25.2}%
\contentsline {subsection}{\numberline {25.2.1}Implementação em Python}{220}{subsection.25.2.1}%
\contentsline {section}{\numberline {25.3}Camadas de Poooling: Reduzindo a Dimensionalidade}{222}{section.25.3}%
\contentsline {subsection}{\numberline {25.3.1}Max Pooling}{222}{subsection.25.3.1}%
\contentsline {subsubsection}{\numberline {25.3.1.1}Implementação em Python}{222}{subsubsection.25.3.1.1}%
\contentsline {subsection}{\numberline {25.3.2}Average Pooling}{224}{subsection.25.3.2}%
\contentsline {subsubsection}{\numberline {25.3.2.1}Implementação em Python}{224}{subsubsection.25.3.2.1}%
\contentsline {subsection}{\numberline {25.3.3}Global Average Pooling}{225}{subsection.25.3.3}%
\contentsline {subsubsection}{\numberline {25.3.3.1}Implementação em Python}{225}{subsubsection.25.3.3.1}%
\contentsline {section}{\numberline {25.4}Camada Flatten: Achatando os Dados}{226}{section.25.4}%
\contentsline {subsection}{\numberline {25.4.1}Implementação em Python}{226}{subsection.25.4.1}%
\contentsline {section}{\numberline {25.5}Criando uma CNN}{227}{section.25.5}%
\contentsline {section}{\numberline {25.6}Detecção de Objetos}{227}{section.25.6}%
\contentsline {section}{\numberline {25.7}Redes Totalmente Convolucionais (FCNs)}{227}{section.25.7}%
\contentsline {section}{\numberline {25.8}You Only Look Once (YOLO)}{227}{section.25.8}%
\contentsline {section}{\numberline {25.9}Algumas Arquiteturas de CNNs}{227}{section.25.9}%
\contentsline {subsection}{\numberline {25.9.1}LeNet-5}{227}{subsection.25.9.1}%
\contentsline {subsection}{\numberline {25.9.2}AlexNet}{227}{subsection.25.9.2}%
\contentsline {subsection}{\numberline {25.9.3}GoogLeNet}{227}{subsection.25.9.3}%
\contentsline {subsection}{\numberline {25.9.4}VGGNet}{227}{subsection.25.9.4}%
\contentsline {subsection}{\numberline {25.9.5}ResNet}{227}{subsection.25.9.5}%
\contentsline {subsection}{\numberline {25.9.6}Xception}{227}{subsection.25.9.6}%
\contentsline {subsection}{\numberline {25.9.7}SENet}{227}{subsection.25.9.7}%
\setlength {\cftchapterindent }{0em} \setlength {\cftchapternumwidth }{\cftlastnumwidth }
\contentsline {chapter}{\chapternumberline {26}\MakeTextUppercase []{Redes Residuais (ResNets)}}{229}{chapter.26}%
\setlength {\cftchapterindent }{0em} \setlength {\cftchapternumwidth }{\cftlastnumwidth }
\contentsline {chapter}{\chapternumberline {27}\MakeTextUppercase []{Redes Neurais Recorrentes (RNN)}}{231}{chapter.27}%
\contentsline {section}{\numberline {27.1}Exemplo Ilustrativo}{231}{section.27.1}%
\contentsline {section}{\numberline {27.2}Neurônios e Células Recorrentes}{231}{section.27.2}%
\contentsline {subsection}{\numberline {27.2.1}Implementação em Python}{231}{subsection.27.2.1}%
\contentsline {section}{\numberline {27.3}Células de Memória}{231}{section.27.3}%
\contentsline {subsection}{\numberline {27.3.1}Implementação em Python}{231}{subsection.27.3.1}%
\contentsline {section}{\numberline {27.4}Criando uma RNN}{231}{section.27.4}%
\contentsline {section}{\numberline {27.5}O Problema da Memória de Curto Prazo}{231}{section.27.5}%
\contentsline {subsection}{\numberline {27.5.1}Células LSTM}{231}{subsection.27.5.1}%
\contentsline {subsection}{\numberline {27.5.2}Conexões Peephole}{231}{subsection.27.5.2}%
\contentsline {subsection}{\numberline {27.5.3}Células GRU}{231}{subsection.27.5.3}%
\setlength {\cftchapterindent }{0em} \setlength {\cftchapternumwidth }{\cftlastnumwidth }
\contentsline {chapter}{\chapternumberline {28}\MakeTextUppercase []{Técnicas para Melhorar o Desempenho de Redes Neurais}}{233}{chapter.28}%
\contentsline {section}{\numberline {28.1}Técnicas de Inicialização}{233}{section.28.1}%
\contentsline {section}{\numberline {28.2}Reguralização L1 e L2}{233}{section.28.2}%
\contentsline {section}{\numberline {28.3}Normalização}{233}{section.28.3}%
\contentsline {subsection}{\numberline {28.3.1}Normalização de Camadas}{233}{subsection.28.3.1}%
\contentsline {subsection}{\numberline {28.3.2}Normalização de Batch}{233}{subsection.28.3.2}%
\contentsline {section}{\numberline {28.4}Cliping do Gradiente}{233}{section.28.4}%
\contentsline {section}{\numberline {28.5}Dropout: Menos Neurônios Mais Aprendizado}{233}{section.28.5}%
\contentsline {section}{\numberline {28.6}Data Augmentation}{233}{section.28.6}%
\setlength {\cftchapterindent }{0em} \setlength {\cftchapternumwidth }{\cftlastnumwidth }
\contentsline {chapter}{\chapternumberline {29}\MakeTextUppercase []{Transformers}}{235}{chapter.29}%
\contentsline {section}{\numberline {29.1}As Limitações das RNNs: O Gargalo Sequencial}{235}{section.29.1}%
\contentsline {section}{\numberline {29.2}A Ideia Central: Self-Attention (Query, Key, Value)}{235}{section.29.2}%
\contentsline {section}{\numberline {29.3}Escalando a Atenção: Multi-Head Attention}{235}{section.29.3}%
\contentsline {section}{\numberline {29.4}A Arquitetura Completa: O Bloco Transformer}{235}{section.29.4}%
\contentsline {section}{\numberline {29.5}Entendendo a Posição: Codificação Posicional}{235}{section.29.5}%
\contentsline {section}{\numberline {29.6}As Três Grandes Arquiteturas}{235}{section.29.6}%
\contentsline {subsection}{\numberline {29.6.1}Encoder-Only (Ex: BERT): Para tarefas de entendimento}{235}{subsection.29.6.1}%
\contentsline {subsection}{\numberline {29.6.2}Decoder-Only (Ex: GPT): Para tarefas de geração}{235}{subsection.29.6.2}%
\contentsline {subsection}{\numberline {29.6.3}Encoder-Decoder (Ex: T5): Para tarefas de tradução/sumarização}{235}{subsection.29.6.3}%
\contentsline {section}{\numberline {29.7}Além do Texto: Vision Transformers (ViT)}{235}{section.29.7}%
\setlength {\cftchapterindent }{0em} \setlength {\cftchapternumwidth }{\cftlastnumwidth }
\contentsline {chapter}{\chapternumberline {30}\MakeTextUppercase []{Redes Adversárias Generativas (GANs)}}{237}{chapter.30}%
\setlength {\cftchapterindent }{0em} \setlength {\cftchapternumwidth }{\cftlastnumwidth }
\contentsline {chapter}{\chapternumberline {31}\MakeTextUppercase []{Mixture of Experts (MoE)}}{239}{chapter.31}%
\setlength {\cftchapterindent }{0em} \setlength {\cftchapternumwidth }{\cftlastnumwidth }
\contentsline {chapter}{\chapternumberline {32}\MakeTextUppercase []{Modelos de Difusão}}{241}{chapter.32}%
\setlength {\cftchapterindent }{0em} \setlength {\cftchapternumwidth }{\cftlastnumwidth }
\contentsline {chapter}{\chapternumberline {33}\MakeTextUppercase []{Redes Neurais de Grafos (GNNs)}}{243}{chapter.33}%
\contentsline {part}{\partnumberline {VI}\MakeTextUppercase []{Apêndices}}{245}{part.6}%
\setlength {\cftchapterindent }{0em} \setlength {\cftchapternumwidth }{\cftlastnumwidth }
\contentsline {appendix}{\chapternumberline {A}\MakeTextUppercase []{Comparativo dos Otimizadores}}{247}{appendix.A}%
\contentsline {section}{\numberline {A.1}Otimizadores Clássicos}{247}{section.A.1}%
\contentsline {subsection}{\numberline {A.1.1}Gradiente Descendente (GD)}{247}{subsection.A.1.1}%
\contentsline {subsection}{\numberline {A.1.2}Gradiente Descendente Estocástico (SGD)}{247}{subsection.A.1.2}%
\contentsline {subsection}{\numberline {A.1.3}Gradiente Descendente com Momento}{248}{subsection.A.1.3}%
\contentsline {subsection}{\numberline {A.1.4}Gradiente Acelerado de Nesterov (NAG)}{248}{subsection.A.1.4}%
\contentsline {section}{\numberline {A.2}Otimizadores Adaptativos Modernos}{249}{section.A.2}%
\contentsline {subsection}{\numberline {A.2.1}AdaGrad (Adaptive Gradient Algorithm)}{249}{subsection.A.2.1}%
\contentsline {subsection}{\numberline {A.2.2}RMSProp (Root Mean Square Propagation)}{249}{subsection.A.2.2}%
\contentsline {subsection}{\numberline {A.2.3}Adam (Adaptive Moment Estimation)}{250}{subsection.A.2.3}%
\contentsline {subsection}{\numberline {A.2.4}AdaMax}{250}{subsection.A.2.4}%
\contentsline {subsection}{\numberline {A.2.5}Nadam (Nesterov-accelerated Adam)}{250}{subsection.A.2.5}%
\contentsline {subsection}{\numberline {A.2.6}AdamW (Adam with Decoupled Weight Decay)}{251}{subsection.A.2.6}%
\setlength {\cftchapterindent }{0em} \setlength {\cftchapternumwidth }{\cftlastnumwidth }
\contentsline {appendix}{\chapternumberline {B}\MakeTextUppercase []{Comparativo das Funções de Ativação}}{253}{appendix.B}%
\contentsline {section}{\numberline {B.1}Família Sigmoidal}{253}{section.B.1}%
\contentsline {subsection}{\numberline {B.1.1}Sigmoide}{253}{subsection.B.1.1}%
\contentsline {subsection}{\numberline {B.1.2}Tangente Hiperbólica (Tanh)}{253}{subsection.B.1.2}%
\contentsline {subsection}{\numberline {B.1.3}Softsign}{254}{subsection.B.1.3}%
\contentsline {subsection}{\numberline {B.1.4}Hard Sigmoid}{254}{subsection.B.1.4}%
\contentsline {subsection}{\numberline {B.1.5}Hard Tanh}{255}{subsection.B.1.5}%
\contentsline {section}{\numberline {B.2}Família Retificadora}{255}{section.B.2}%
\contentsline {subsection}{\numberline {B.2.1}ReLU (Rectified Linear Unit)}{255}{subsection.B.2.1}%
\contentsline {subsection}{\numberline {B.2.2}Leaky ReLU (LReLU)}{256}{subsection.B.2.2}%
\contentsline {subsection}{\numberline {B.2.3}Parametric ReLU (PReLU)}{257}{subsection.B.2.3}%
\contentsline {subsection}{\numberline {B.2.4}ELU (Exponential Linear Unit)}{257}{subsection.B.2.4}%
\contentsline {subsection}{\numberline {B.2.5}SELU (Scaled Exponential Linear Unit)}{258}{subsection.B.2.5}%
\contentsline {subsection}{\numberline {B.2.6}GELU (Gaussian Error Linear Unit)}{258}{subsection.B.2.6}%
\setlength {\cftchapterindent }{0em} \setlength {\cftchapternumwidth }{\cftlastnumwidth }
\contentsline {appendix}{\chapternumberline {C}\MakeTextUppercase []{Comparativo das Funções de Perda}}{259}{appendix.C}%
\contentsline {section}{\numberline {C.1}Funções de Perda para Regressão}{259}{section.C.1}%
\contentsline {subsection}{\numberline {C.1.1}Erro Quadrático Médio (MSE)}{259}{subsection.C.1.1}%
\contentsline {subsection}{\numberline {C.1.2}Erro Absoluto Médio (MAE)}{259}{subsection.C.1.2}%
\contentsline {subsection}{\numberline {C.1.3}Huber Loss}{260}{subsection.C.1.3}%
\contentsline {subsection}{\numberline {C.1.4}Log-Cosh Loss}{261}{subsection.C.1.4}%
\contentsline {subsection}{\numberline {C.1.5}Quantile Loss (Pinball Loss)}{261}{subsection.C.1.5}%
\contentsline {section}{\numberline {C.2}Funções de Perda para Classificação}{262}{section.C.2}%
\contentsline {subsection}{\numberline {C.2.1}Entropia Cruzada Binária (BCE)}{262}{subsection.C.2.1}%
\contentsline {subsection}{\numberline {C.2.2}Hinge Loss}{262}{subsection.C.2.2}%
\contentsline {subsection}{\numberline {C.2.3}Entropia Cruzada Categórica (CCE)}{263}{subsection.C.2.3}%
\contentsline {subsection}{\numberline {C.2.4}Focal Loss}{263}{subsection.C.2.4}%
\setlength {\cftchapterindent }{0em} \setlength {\cftchapternumwidth }{\cftlastnumwidth }
\contentsline {appendix}{\chapternumberline {D}\MakeTextUppercase []{Comparativo das Métricas de Avaliação}}{265}{appendix.D}%
\contentsline {section}{\numberline {D.1}Métricas para Classificação}{265}{section.D.1}%
\contentsline {subsection}{\numberline {D.1.1}Acurácia (Accuracy)}{265}{subsection.D.1.1}%
\contentsline {subsection}{\numberline {D.1.2}Precisão (Precision)}{265}{subsection.D.1.2}%
\contentsline {subsection}{\numberline {D.1.3}Revocação (Recall / Sensibilidade)}{266}{subsection.D.1.3}%
\contentsline {subsection}{\numberline {D.1.4}F1-Score}{266}{subsection.D.1.4}%
\contentsline {subsection}{\numberline {D.1.5}AUC-ROC}{267}{subsection.D.1.5}%
\contentsline {section}{\numberline {D.2}Métricas para Regressão}{268}{section.D.2}%
\contentsline {subsection}{\numberline {D.2.1}RMSE (Root Mean Square Error)}{268}{subsection.D.2.1}%
\contentsline {subsection}{\numberline {D.2.2}R² (Coeficiente de Determinação)}{268}{subsection.D.2.2}%
\vspace {\cftbeforechapterskip }
\setlength {\cftchapterindent }{\cftlastnumwidth } \setlength {\cftchapternumwidth }{2em}
\contentsline {chapter}{Referências}{271}{section*.193}%
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
\babel@toc {brazil}{}\relax 
