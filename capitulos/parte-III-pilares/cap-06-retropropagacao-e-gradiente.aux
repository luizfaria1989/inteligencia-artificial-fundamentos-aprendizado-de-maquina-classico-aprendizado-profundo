\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\setlength  {\cftchapterindent }{0em} \setlength  {\cftchapternumwidth }{\cftlastnumwidth }}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {6}\MakeTextUppercase    []{O Algoritmo da Repropropagação e Os Otimizadores Baseados em Gradiente}}{21}{chapter.6}\protected@file@percent }
\newlabel{cap:retropropagacao-gradiente}{{6}{21}{\texorpdfstring {\MakeTextUppercase {\tempf@rtoc }}{\tempf@rtoc }}{chapter.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}O Método do Gradiente Descendente: A Inspiração de Todos}{22}{section.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.1}Exemplo Ilustrativo: Cadeia de Montanhas}{22}{subsection.6.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.2}O Método em Si}{23}{subsection.6.1.2}\protected@file@percent }
\newlabel{eq:metodo-do-gradiente}{{6.1}{23}{O Método em Si}{equation.6.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Comparativo do tamanho de passos em uma função polinomial.}}{24}{figure.6.1}\protected@file@percent }
\newlabel{fig:comparativo-tamanho-do-passo}{{1}{24}{Comparativo do tamanho de passos em uma função polinomial}{figure.6.1}{}}
\newlabel{fig:funcao-convexa}{{6.1.2}{25}{O Método em Si}{figure.6.1}{}}
\newlabel{fig-funcao-nao-convexa}{{6.1.2}{25}{O Método em Si}{figure.6.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Comparação entre funções 3D convexas e não-convexas.}}{25}{figure.6.2}\protected@file@percent }
\newlabel{fig:funcao-convexa-nao-convexa}{{2}{25}{Comparação entre funções 3D convexas e não-convexas}{figure.6.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.3}Implementação em Python}{25}{subsection.6.1.3}\protected@file@percent }
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces O Método do Gradiente (Descida do Gradiente)}}{25}{algorithm.1}\protected@file@percent }
\newlabel{alg:gradient_descent}{{1}{25}{Implementação em Python}{algorithm.1}{}}
\newlabel{lst:gd_class}{{6.1.3}{27}{Implementação em Python}{algorithm.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}A Retropropagação: Aprendendo com os Erros}{27}{section.6.2}\protected@file@percent }
\newlabel{eq:neuronio-camada-densa}{{6.2}{28}{A Retropropagação: Aprendendo com os Erros}{equation.6.2}{}}
\newlabel{eq:sigmoide}{{6.3}{28}{A Retropropagação: Aprendendo com os Erros}{equation.6.3}{}}
\newlabel{eq:mse}{{6.4}{29}{A Retropropagação: Aprendendo com os Erros}{equation.6.4}{}}
\newlabel{eq:gradiente-do-erro-em-relacao-a-entrada-de-um-neuronio}{{6.5}{31}{A Retropropagação: Aprendendo com os Erros}{equation.6.5}{}}
\newlabel{eq:gradiente-do-erro-em-relacao-a-um-peso-de-um-neuronio}{{6.6}{32}{A Retropropagação: Aprendendo com os Erros}{equation.6.6}{}}
\newlabel{eq:gradiente-do-erro-em-relacao-a-um-vies-de-um-neuronio}{{6.7}{33}{A Retropropagação: Aprendendo com os Erros}{equation.6.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.1}Utilizando o Gradiente Descendente para Atualizar os Pesos e Vieses}{34}{subsection.6.2.1}\protected@file@percent }
\newlabel{eq:regra-de-atualizacao-de-um-peso-atraves-do-metodo-do-gradiente}{{6.8}{34}{Utilizando o Gradiente Descendente para Atualizar os Pesos e Vieses}{equation.6.8}{}}
\newlabel{eq:regra-de-atualizacao-de-um-vies-atraves-do-metodo-do-gradiente}{{6.9}{34}{Utilizando o Gradiente Descendente para Atualizar os Pesos e Vieses}{equation.6.9}{}}
\newlabel{eq:regra-de-atualizacao-do-vetor-de-pesos-atraves-do-metodo-do-gradiente}{{6.10}{35}{Utilizando o Gradiente Descendente para Atualizar os Pesos e Vieses}{equation.6.10}{}}
\newlabel{eq:regra-de-atualizacao-do-vetor-de-vieses-atraves-do-metodo-do-gradiente}{{6.11}{35}{Utilizando o Gradiente Descendente para Atualizar os Pesos e Vieses}{equation.6.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.2}Entendendo Como o Gradiente É Propagado ao Longo de Muitas